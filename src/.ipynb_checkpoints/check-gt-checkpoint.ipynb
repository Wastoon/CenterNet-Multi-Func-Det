{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import _init_paths\n",
    "\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from opts import opts\n",
    "from models.model import create_model, load_model, save_model\n",
    "from models.data_parallel import DataParallel\n",
    "from logger import Logger\n",
    "from datasets.dataset_factory import get_dataset\n",
    "from trains.train_factory import train_factory\n",
    "\n",
    "\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "import cv2\n",
    "import os\n",
    "from utils.image import flip, color_aug\n",
    "from utils.image import get_affine_transform, affine_transform\n",
    "from utils.image import gaussian_radius, draw_umich_gaussian, draw_msra_gaussian\n",
    "from utils.image import draw_dense_reg\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fix size testing.\n",
      "training chunk_sizes: [32]\n",
      "The output will be saved to  /data/mry/code/CenterNet/src/lib/../../exp/ctdet/coco\n",
      "==> initializing coco 2014 train data.\n",
      "loading annotations into memory...\n",
      "Done (t=14.11s)\n",
      "creating index...\n",
      "index created!\n",
      "Loaded train 82783 samples\n"
     ]
    }
   ],
   "source": [
    "dataset = 'coco'\n",
    "task = 'ctdet'\n",
    "opt = opts().parse(args=[])\n",
    "Dataset = get_dataset(dataset, task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fix size testing.\n",
      "training chunk_sizes: [32]\n",
      "The output will be saved to  /data/mry/code/CenterNet/src/lib/../../exp/ctdet/coco\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt = opts().parse(args=[])\n",
    "opt.gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fix size testing.\n",
      "training chunk_sizes: [32]\n",
      "The output will be saved to  /data/mry/code/CenterNet/src/lib/../../exp/ctdet/coco\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Namespace' object has no attribute 'point_flags'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-1377673ef02f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'0'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoint_flags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mpoints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_spec_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mpoints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoints_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Namespace' object has no attribute 'point_flags'"
     ]
    }
   ],
   "source": [
    "\n",
    "opt = opts().parse(args=[])\n",
    "class generate_spec_points():\n",
    "    \n",
    "    def __init__(self, points_list):\n",
    "        super(generate_spec_points, self).__init__()\n",
    "        self.points_list = [int(i) for i in points_list]\n",
    "        self.points_num = len(self.points_list)\n",
    "        \n",
    "a = ['0', '1']\n",
    "a = opt.point_flags\n",
    "points = generate_spec_points(a)\n",
    "points.points_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridNeighborDetDataset(data.Dataset):\n",
    "  def _coco_box_to_bbox(self, box):\n",
    "    bbox = np.array([box[0], box[1], box[0] + box[2], box[1] + box[3]],\n",
    "                    dtype=np.float32)\n",
    "    return bbox\n",
    "\n",
    "  def _get_border(self, border, size):\n",
    "    i = 1\n",
    "    while size - border // i <= border // i:\n",
    "        i *= 2\n",
    "    return border // i\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    img_id = self.images[index]\n",
    "    file_name = self.coco.loadImgs(ids=[img_id])[0]['file_name']\n",
    "    img_path = os.path.join(self.img_dir, file_name)\n",
    "    ann_ids = self.coco.getAnnIds(imgIds=[img_id])\n",
    "    anns = self.coco.loadAnns(ids=ann_ids)\n",
    "    num_objs = min(len(anns), self.max_objs)\n",
    "\n",
    "    img = cv2.imread(img_path)\n",
    "\n",
    "    height, width = img.shape[0], img.shape[1]\n",
    "    c = np.array([img.shape[1] / 2., img.shape[0] / 2.], dtype=np.float32)\n",
    "    if self.opt.keep_res:\n",
    "      input_h = (height | self.opt.pad) + 1\n",
    "      input_w = (width | self.opt.pad) + 1\n",
    "      s = np.array([input_w, input_h], dtype=np.float32)\n",
    "    else:\n",
    "      s = max(img.shape[0], img.shape[1]) * 1.0\n",
    "      input_h, input_w = self.opt.input_h, self.opt.input_w\n",
    "    \n",
    "    flipped = False\n",
    "    if self.split == 'train':\n",
    "      if not self.opt.not_rand_crop:\n",
    "        s = s * np.random.choice(np.arange(0.6, 1.4, 0.1))\n",
    "        w_border = self._get_border(128, img.shape[1])\n",
    "        h_border = self._get_border(128, img.shape[0])\n",
    "        c[0] = np.random.randint(low=w_border, high=img.shape[1] - w_border)\n",
    "        c[1] = np.random.randint(low=h_border, high=img.shape[0] - h_border)\n",
    "      else:\n",
    "        sf = self.opt.scale\n",
    "        cf = self.opt.shift\n",
    "        c[0] += s * np.clip(np.random.randn()*cf, -2*cf, 2*cf)\n",
    "        c[1] += s * np.clip(np.random.randn()*cf, -2*cf, 2*cf)\n",
    "        s = s * np.clip(np.random.randn()*sf + 1, 1 - sf, 1 + sf)\n",
    "      \n",
    "      if np.random.random() < self.opt.flip:\n",
    "        flipped = True\n",
    "        img = img[:, ::-1, :]\n",
    "        c[0] =  width - c[0] - 1\n",
    "        \n",
    "\n",
    "    trans_input = get_affine_transform(\n",
    "      c, s, 0, [input_w, input_h])\n",
    "    inp = cv2.warpAffine(img, trans_input, \n",
    "                         (input_w, input_h),\n",
    "                         flags=cv2.INTER_LINEAR)\n",
    "    inp = (inp.astype(np.float32) / 255.)\n",
    "    if self.split == 'train' and not self.opt.no_color_aug:\n",
    "      color_aug(self._data_rng, inp, self._eig_val, self._eig_vec)\n",
    "    inp = (inp - self.mean) / self.std\n",
    "    inp = inp.transpose(2, 0, 1)\n",
    "\n",
    "    output_h = input_h // self.opt.down_ratio\n",
    "    output_w = input_w // self.opt.down_ratio\n",
    "    num_classes = self.num_classes\n",
    "    trans_output = get_affine_transform(c, s, 0, [output_w, output_h])\n",
    "\n",
    "    hm = np.zeros((num_classes, output_h, output_w), dtype=np.float32)\n",
    "    wh = np.zeros((self.max_objs, 2), dtype=np.float32)\n",
    "    dense_wh = np.zeros((2, output_h, output_w), dtype=np.float32)\n",
    "    reg = np.zeros((self.max_objs, 2), dtype=np.float32)\n",
    "    ind = np.zeros((self.max_objs), dtype=np.int64)\n",
    "    reg_mask = np.zeros((self.max_objs), dtype=np.uint8)\n",
    "    cat_spec_wh = np.zeros((self.max_objs, num_classes * 2), dtype=np.float32)\n",
    "    cat_spec_mask = np.zeros((self.max_objs, num_classes * 2), dtype=np.uint8)\n",
    "    \n",
    "    draw_gaussian = draw_msra_gaussian if self.opt.mse_loss else \\\n",
    "                    draw_umich_gaussian\n",
    "\n",
    "    gt_det = []\n",
    "    for k in range(num_objs):\n",
    "      ann = anns[k]\n",
    "      bbox = self._coco_box_to_bbox(ann['bbox'])\n",
    "      cls_id = int(self.cat_ids[ann['category_id']])\n",
    "      if flipped:\n",
    "        bbox[[0, 2]] = width - bbox[[2, 0]] - 1\n",
    "      bbox[:2] = affine_transform(bbox[:2], trans_output)\n",
    "      bbox[2:] = affine_transform(bbox[2:], trans_output)\n",
    "      bbox[[0, 2]] = np.clip(bbox[[0, 2]], 0, output_w - 1)\n",
    "      bbox[[1, 3]] = np.clip(bbox[[1, 3]], 0, output_h - 1)\n",
    "      h, w = bbox[3] - bbox[1], bbox[2] - bbox[0]\n",
    "      if h > 0 and w > 0:\n",
    "        radius = gaussian_radius((math.ceil(h), math.ceil(w)))\n",
    "        radius = max(0, int(radius))\n",
    "        radius = self.opt.hm_gauss if self.opt.mse_loss else radius\n",
    "        ct = np.array(\n",
    "          [(bbox[0] + bbox[2]) / 2, (bbox[1] + bbox[3]) / 2], dtype=np.float32)\n",
    "        ct_int = ct.astype(np.int32)\n",
    "        draw_gaussian(hm[cls_id], ct_int, radius)\n",
    "        wh[k] = 1. * w, 1. * h\n",
    "        ind[k] = ct_int[1] * output_w + ct_int[0]\n",
    "        reg[k] = ct - ct_int\n",
    "        reg_mask[k] = 1\n",
    "        cat_spec_wh[k, cls_id * 2: cls_id * 2 + 2] = wh[k]\n",
    "        cat_spec_mask[k, cls_id * 2: cls_id * 2 + 2] = 1\n",
    "        if self.opt.dense_wh:\n",
    "          draw_dense_reg(dense_wh, hm.max(axis=0), ct_int, wh[k], radius)\n",
    "        gt_det.append([ct[0] - w / 2, ct[1] - h / 2, \n",
    "                       ct[0] + w / 2, ct[1] + h / 2, 1, cls_id])\n",
    "    \n",
    "    ret = {'input': inp, 'hm': hm, 'reg_mask': reg_mask, 'ind': ind, 'wh': wh}\n",
    "    if self.opt.dense_wh:\n",
    "      hm_a = hm.max(axis=0, keepdims=True)\n",
    "      dense_wh_mask = np.concatenate([hm_a, hm_a], axis=0)\n",
    "      ret.update({'dense_wh': dense_wh, 'dense_wh_mask': dense_wh_mask})\n",
    "      del ret['wh']\n",
    "    elif self.opt.cat_spec_wh:\n",
    "      ret.update({'cat_spec_wh': cat_spec_wh, 'cat_spec_mask': cat_spec_mask})\n",
    "      del ret['wh']\n",
    "    if self.opt.reg_offset:\n",
    "      ret.update({'reg': reg})\n",
    "    if self.opt.debug > 0 or not self.split == 'train':\n",
    "      gt_det = np.array(gt_det, dtype=np.float32) if len(gt_det) > 0 else \\\n",
    "               np.zeros((1, 6), dtype=np.float32)\n",
    "      meta = {'c': c, 's': s, 'gt_det': gt_det, 'img_id': img_id}\n",
    "      ret['meta'] = meta\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> initializing coco 2014 train data.\n",
      "loading annotations into memory...\n",
      "Done (t=14.09s)\n",
      "creating index...\n",
      "index created!\n",
      "Loaded train 82783 samples\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "  Dataset(opt, 'train'),\n",
    "  batch_size=opt.batch_size,\n",
    "  shuffle=True,\n",
    "  num_workers=opt.num_workers,\n",
    "  pin_memory=True,\n",
    "  drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> initializing coco 2014 train data.\n",
      "loading annotations into memory...\n",
      "Done (t=21.54s)\n",
      "creating index...\n",
      "index created!\n",
      "Loaded train 82783 samples\n"
     ]
    }
   ],
   "source": [
    "test = Dataset(opt, 'train')\n",
    "sample = test[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input', 'hm', 'reg_mask', 'ind', 'wh', 'reg'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(128, 2)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(sample.keys())\n",
    "sample['wh'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/mry/code/CenterNet/src'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fix size testing.\n",
      "training chunk_sizes: [32]\n",
      "The output will be saved to  /data/mry/code/CenterNet/src/lib/../../exp/ctdet/coco\n",
      "heads {'hm': 80, 'wh': 2, 'reg': 2}\n",
      "Namespace(K=4, aggr_weight=0.0, agnostic_ex=False, arch='hourglass', aug_ddd=0.5, aug_rot=0, batch_size=32, cat_spec_wh=False, center_thresh=0.1, chunk_sizes=[32], data_dir='/data/mry/DataSet/', dataset='coco', debug=0, debug_dir='/data/mry/code/CenterNet/src/lib/../../exp/ctdet/coco/debug', debugger_theme='white', demo='', dense_hp=False, dense_wh=False, dep_weight=1, det_output_path='', dim_weight=1, down_ratio=4, eval_oracle_dep=False, eval_oracle_hm=False, eval_oracle_hmhp=False, eval_oracle_hp_offset=False, eval_oracle_kps=False, eval_oracle_offset=False, eval_oracle_wh=False, exp_dir='/data/mry/code/CenterNet/src/lib/../../exp/ctdet', exp_id='coco', fix_res=True, flip=0, flip_test=False, gpus=[0], gpus_str='1', head_conv=64, heads={'hm': 80, 'wh': 2, 'reg': 2}, hide_data_time=False, hm_hp=True, hm_hp_weight=1, hm_weight=1, hp_weight=1, input_h=512, input_res=512, input_w=512, keep_inp_res_prob=0, keep_res=False, kitti_split='3dop', load_model='', logger_iteration=1, lr=0.000125, lr_step=[90, 120], master_batch_size=32, mean=array([[[0.40789655, 0.44719303, 0.47026116]]], dtype=float32), metric='loss', mse_loss=False, nms=False, no_color_aug=False, norm_wh=False, not_cuda_benchmark=False, not_hm_hp=False, not_prefetch_test=False, not_rand_crop=False, not_reg_bbox=False, not_reg_hp_offset=False, not_reg_offset=False, num_classes=80, num_epochs=60, num_iters=-1, num_stacks=2, num_workers=4, off_weight=1, output_h=128, output_res=128, output_w=128, pad=127, peak_thresh=0.2, print_iter=0, rect_mask=False, reg_bbox=True, reg_hp_offset=True, reg_loss='l1', reg_offset=True, reg_or_reghm=False, resume=False, root_dir='/data/mry/code/CenterNet/src/lib/../..', rot_weight=1, rotate=0, save_all=False, save_dir='/data/mry/code/CenterNet/src/lib/../../exp/ctdet/coco', scale=0.4, scores_thresh=0.1, seed=317, shift=0.1, std=array([[[0.2886383 , 0.27408165, 0.27809834]]], dtype=float32), task='ctdet', test=False, test_scales=[1.0], test_split='full', trainval=False, val_intervals=5, vis_thresh=0.1, wh_weight=0.1)\n",
      "Creating model...\n",
      "Setting up data...\n",
      "==> initializing coco 2014 val data.\n",
      "loading annotations into memory...\n",
      "Done (t=7.50s)\n",
      "creating index...\n",
      "index created!\n",
      "Loaded val 40504 samples\n",
      "==> initializing coco 2014 train data.\n",
      "loading annotations into memory...\n",
      "Done (t=15.38s)\n",
      "creating index...\n",
      "index created!\n",
      "Loaded train 82783 samples\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'a' is an invalid keyword argument for this function",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-dd8316ed853f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m   \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m   \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-28-dd8316ed853f>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(opt)\u001b[0m\n\u001b[1;32m     65\u001b[0m       \u001b[0mdrop_last\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m   )\n\u001b[0;32m---> 67\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Starting training...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m   \u001b[0mbest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'a' is an invalid keyword argument for this function"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import _init_paths\n",
    "\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from opts import opts\n",
    "from models.model import create_model, load_model, save_model\n",
    "from models.data_parallel import DataParallel\n",
    "from logger import Logger\n",
    "from datasets.dataset_factory import get_dataset\n",
    "from trains.train_factory import train_factory\n",
    "\n",
    "\n",
    "def main(opt):\n",
    "  torch.manual_seed(opt.seed)\n",
    "  torch.backends.cudnn.benchmark = not opt.not_cuda_benchmark and not opt.test\n",
    "  Dataset = get_dataset(opt.dataset, opt.task)\n",
    "  #Dataset = get_dataset(opt.dataset)\n",
    "  opt = opts().update_dataset_info_and_set_heads(opt, Dataset)\n",
    "  print(opt)\n",
    "\n",
    "  logger = Logger(opt)\n",
    "\n",
    "  os.environ['CUDA_VISIBLE_DEVICES'] = opt.gpus_str\n",
    "  opt.device = torch.device('cuda' if opt.gpus[0] >= 0 else 'cpu')\n",
    "  \n",
    "  print('Creating model...')\n",
    "  model = create_model(opt.arch, opt.heads, opt.head_conv)\n",
    "  optimizer = torch.optim.Adam(model.parameters(), opt.lr)\n",
    "  start_epoch = 0\n",
    "  if opt.load_model != '':\n",
    "    model, optimizer, start_epoch = load_model(\n",
    "      model, opt.load_model, optimizer, opt.resume, opt.lr, opt.lr_step)\n",
    "\n",
    "  Trainer = train_factory[opt.task]\n",
    "  trainer = Trainer(opt, model, optimizer)\n",
    "  trainer.set_device(opt.gpus, opt.chunk_sizes, opt.device)\n",
    "\n",
    "  print('Setting up data...')\n",
    "  val_loader = torch.utils.data.DataLoader(\n",
    "      Dataset(opt, 'val'),\n",
    "      batch_size=1,\n",
    "      shuffle=False,\n",
    "      num_workers=1,\n",
    "      pin_memory=True,\n",
    "      drop_last=True\n",
    "  )\n",
    "\n",
    "  if opt.test:\n",
    "    _, preds = trainer.val(0, val_loader)\n",
    "    val_loader.dataset.run_eval(preds, opt.save_dir)\n",
    "    return\n",
    "\n",
    "  train_loader = torch.utils.data.DataLoader(\n",
    "      Dataset(opt, 'train'),\n",
    "      batch_size=opt.batch_size,\n",
    "      shuffle=True,\n",
    "      num_workers=opt.num_workers,\n",
    "      pin_memory=True,\n",
    "      drop_last=True\n",
    "  )\n",
    "  print('Starting training...')\n",
    "  best = 1e10\n",
    "  for epoch in range(start_epoch + 1, opt.num_epochs + 1):\n",
    "    mark = epoch if opt.save_all else 'last'\n",
    "    log_dict_train, _ = trainer.train(epoch, train_loader, logger)\n",
    "    logger.write_epoch('epoch: {} |'.format(epoch))\n",
    "    for k, v in log_dict_train.items():\n",
    "      logger.scalar_summary('train_epoch_{}'.format(k), v, epoch)\n",
    "      logger.write_epoch('{} {:8f} | '.format(k, v))\n",
    "    if opt.val_intervals > 0 and epoch % opt.val_intervals == 0:\n",
    "      save_model(os.path.join(opt.save_dir, 'model_{}.pth'.format(mark)), \n",
    "                 epoch, model, optimizer)\n",
    "      with torch.no_grad():\n",
    "        log_dict_val, preds = trainer.val(epoch, val_loader)\n",
    "      for k, v in log_dict_val.items():\n",
    "        logger.scalar_summary('val_epoch_{}'.format(k), v, epoch)\n",
    "        logger.write_epoch('{} {:8f} | '.format(k, v))\n",
    "      if log_dict_val[opt.metric] < best:\n",
    "        best = log_dict_val[opt.metric]\n",
    "        save_model(os.path.join(opt.save_dir, 'model_best.pth'), \n",
    "                   epoch, model)\n",
    "    else:\n",
    "      save_model(os.path.join(opt.save_dir, 'model_last.pth'), \n",
    "                 epoch, model, optimizer)\n",
    "    logger.write_epoch('\\n')\n",
    "    if epoch in opt.lr_step:\n",
    "      save_model(os.path.join(opt.save_dir, 'model_{}.pth'.format(epoch)), \n",
    "                 epoch, model, optimizer)\n",
    "      lr = opt.lr * (0.1 ** (opt.lr_step.index(epoch) + 1))\n",
    "      print('Drop LR to', lr)\n",
    "      for param_group in optimizer.param_groups:\n",
    "          param_group['lr'] = lr\n",
    "  logger.close_epoch()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  opt = opts().parse(args=[])\n",
    "  main(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3f786850e387>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'a' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:centerpoint]",
   "language": "python",
   "name": "conda-env-centerpoint-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
